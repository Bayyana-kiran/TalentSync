{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Resume.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat=data['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Resume_html</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16852973</td>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22323967</td>\n",
       "      <td>HR SPECIALIST, US HR OPERATIONS      ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33176873</td>\n",
       "      <td>HR DIRECTOR       Summary      Over 2...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27018550</td>\n",
       "      <td>HR SPECIALIST       Summary    Dedica...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17812897</td>\n",
       "      <td>HR MANAGER         Skill Highlights  ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                         Resume_str  \\\n",
       "0  16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...   \n",
       "1  22323967           HR SPECIALIST, US HR OPERATIONS      ...   \n",
       "2  33176873           HR DIRECTOR       Summary      Over 2...   \n",
       "3  27018550           HR SPECIALIST       Summary    Dedica...   \n",
       "4  17812897           HR MANAGER         Skill Highlights  ...   \n",
       "\n",
       "                                         Resume_html Category  \n",
       "0  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "1  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "2  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "3  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "4  <div class=\"fontsize fontface vmargins hmargin...       HR  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2484, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HR', 'DESIGNER', 'INFORMATION-TECHNOLOGY', 'TEACHER', 'ADVOCATE',\n",
       "       'BUSINESS-DEVELOPMENT', 'HEALTHCARE', 'FITNESS', 'AGRICULTURE',\n",
       "       'BPO', 'SALES', 'CONSULTANT', 'DIGITAL-MEDIA', 'AUTOMOBILE',\n",
       "       'CHEF', 'FINANCE', 'APPAREL', 'ENGINEERING', 'ACCOUNTANT',\n",
       "       'CONSTRUCTION', 'PUBLIC-RELATIONS', 'BANKING', 'ARTS', 'AVIATION'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbl=LabelEncoder()\n",
    "data['Category']=lbl.fit_transform(data['Category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ACCOUNTANT', 'ADVOCATE', 'AGRICULTURE', 'APPAREL', 'ARTS',\n",
       "       'AUTOMOBILE', 'AVIATION', 'BANKING', 'BPO', 'BUSINESS-DEVELOPMENT',\n",
       "       'CHEF', 'CONSTRUCTION', 'CONSULTANT', 'DESIGNER', 'DIGITAL-MEDIA',\n",
       "       'ENGINEERING', 'FINANCE', 'FITNESS', 'HEALTHCARE', 'HR',\n",
       "       'INFORMATION-TECHNOLOGY', 'PUBLIC-RELATIONS', 'SALES', 'TEACHER'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['Resume_html','ID'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HR SPECIALIST, US HR OPERATIONS      ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HR DIRECTOR       Summary      Over 2...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HR SPECIALIST       Summary    Dedica...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HR MANAGER         Skill Highlights  ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Resume_str  Category\n",
       "0           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...        19\n",
       "1           HR SPECIALIST, US HR OPERATIONS      ...        19\n",
       "2           HR DIRECTOR       Summary      Over 2...        19\n",
       "3           HR SPECIALIST       Summary    Dedica...        19\n",
       "4           HR MANAGER         Skill Highlights  ...        19"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Category'] != 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HR SPECIALIST, US HR OPERATIONS      ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HR DIRECTOR       Summary      Over 2...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HR SPECIALIST       Summary    Dedica...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HR MANAGER         Skill Highlights  ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Resume_str  Category\n",
       "0           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...        19\n",
       "1           HR SPECIALIST, US HR OPERATIONS      ...        19\n",
       "2           HR DIRECTOR       Summary      Over 2...        19\n",
       "3           HR SPECIALIST       Summary    Dedica...        19\n",
       "4           HR MANAGER         Skill Highlights  ...        19"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resume_str    0\n",
       "Category      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Resume_str']=data['Resume_str'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove unwanted characters (replace with whitespace)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Resume_str'] = data['Resume_str'].apply(lambda x: preprocess_text(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Resume_str'] = data['Resume_str'].apply(lambda x: ''.join([c for c in x if c not in string.punctuation]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=data['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hr administrator marketing associate hr admini...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hr specialist us hr operations summary versati...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hr director summary over years experience in r...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hr specialist summary dedicated driven and dyn...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hr manager skill highlights hr skills hr depar...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Resume_str  Category\n",
       "0  hr administrator marketing associate hr admini...        19\n",
       "1  hr specialist us hr operations summary versati...        19\n",
       "2  hr director summary over years experience in r...        19\n",
       "3  hr specialist summary dedicated driven and dyn...        19\n",
       "4  hr manager skill highlights hr skills hr depar...        19"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Resume_str'] = data['Resume_str'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[hr, administrator, marketing, associate, hr, ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[hr, specialist, us, hr, operations, summary, ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[hr, director, summary, over, years, experienc...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hr, specialist, summary, dedicated, driven, a...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[hr, manager, skill, highlights, hr, skills, h...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Resume_str  Category\n",
       "0  [hr, administrator, marketing, associate, hr, ...        19\n",
       "1  [hr, specialist, us, hr, operations, summary, ...        19\n",
       "2  [hr, director, summary, over, years, experienc...        19\n",
       "3  [hr, specialist, summary, dedicated, driven, a...        19\n",
       "4  [hr, manager, skill, highlights, hr, skills, h...        19"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/namanmuktha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data['Resume_str'] = data['Resume_str'].apply(lambda x: [word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[hr, administrator, marketing, associate, hr, ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[hr, specialist, us, hr, operations, summary, ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[hr, director, summary, years, experience, rec...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hr, specialist, summary, dedicated, driven, d...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[hr, manager, skill, highlights, hr, skills, h...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Resume_str  Category\n",
       "0  [hr, administrator, marketing, associate, hr, ...        19\n",
       "1  [hr, specialist, us, hr, operations, summary, ...        19\n",
       "2  [hr, director, summary, years, experience, rec...        19\n",
       "3  [hr, specialist, summary, dedicated, driven, d...        19\n",
       "4  [hr, manager, skill, highlights, hr, skills, h...        19"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/namanmuktha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data['Resume_str'] = data['Resume_str'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[hr, administrator, marketing, associate, hr, ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[hr, specialist, u, hr, operation, summary, ve...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[hr, director, summary, year, experience, recr...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hr, specialist, summary, dedicated, driven, d...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[hr, manager, skill, highlight, hr, skill, hr,...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Resume_str  Category\n",
       "0  [hr, administrator, marketing, associate, hr, ...        19\n",
       "1  [hr, specialist, u, hr, operation, summary, ve...        19\n",
       "2  [hr, director, summary, year, experience, recr...        19\n",
       "3  [hr, specialist, summary, dedicated, driven, d...        19\n",
       "4  [hr, manager, skill, highlight, hr, skill, hr,...        19"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import SnowballStemmer\n",
    "lang=\"english\"\n",
    "steamer=SnowballStemmer(lang)\n",
    "def adding_stemming(tokens):\n",
    "    return [steamer.stem(token) for token in tokens]\n",
    "data[\"Resume_str\"]=data[\"Resume_str\"].apply(adding_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[hr, administr, market, associ, hr, administr,...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[hr, specialist, u, hr, oper, summari, versati...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[hr, director, summari, year, experi, recruit,...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hr, specialist, summari, dedic, driven, dynam...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[hr, manag, skill, highlight, hr, skill, hr, d...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Resume_str  Category\n",
       "0  [hr, administr, market, associ, hr, administr,...        19\n",
       "1  [hr, specialist, u, hr, oper, summari, versati...        19\n",
       "2  [hr, director, summari, year, experi, recruit,...        19\n",
       "3  [hr, specialist, summari, dedic, driven, dynam...        19\n",
       "4  [hr, manag, skill, highlight, hr, skill, hr, d...        19"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=20000)\n",
    "\n",
    "# Assuming 'work_data' is a DataFrame with a 'text' column containing lists of words\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform([\" \".join(doc) for doc in data['Resume_str']])\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Concatenate the 'text' column and the TF-IDF features\n",
    "data = pd.concat([data['Resume_str'].reset_index(drop=True), tfidf_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaahc</th>\n",
       "      <th>aac</th>\n",
       "      <th>aaf</th>\n",
       "      <th>aagi</th>\n",
       "      <th>aam</th>\n",
       "      <th>aami</th>\n",
       "      <th>aap</th>\n",
       "      <th>...</th>\n",
       "      <th>zune</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zutano</th>\n",
       "      <th>zvm</th>\n",
       "      <th>zx</th>\n",
       "      <th>zxx</th>\n",
       "      <th>zynex</th>\n",
       "      <th>zynx</th>\n",
       "      <th>zypher</th>\n",
       "      <th>zyrtec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[hr, administr, market, associ, hr, administr,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[hr, specialist, u, hr, oper, summari, versati...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[hr, director, summari, year, experi, recruit,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hr, specialist, summari, dedic, driven, dynam...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[hr, manag, skill, highlight, hr, skill, hr, d...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Resume_str   aa  aaa  aaahc  aac  \\\n",
       "0  [hr, administr, market, associ, hr, administr,...  0.0  0.0    0.0  0.0   \n",
       "1  [hr, specialist, u, hr, oper, summari, versati...  0.0  0.0    0.0  0.0   \n",
       "2  [hr, director, summari, year, experi, recruit,...  0.0  0.0    0.0  0.0   \n",
       "3  [hr, specialist, summari, dedic, driven, dynam...  0.0  0.0    0.0  0.0   \n",
       "4  [hr, manag, skill, highlight, hr, skill, hr, d...  0.0  0.0    0.0  0.0   \n",
       "\n",
       "   aaf  aagi  aam  aami  aap  ...  zune  zurich  zutano  zvm   zx  zxx  zynex  \\\n",
       "0  0.0   0.0  0.0   0.0  0.0  ...   0.0     0.0     0.0  0.0  0.0  0.0    0.0   \n",
       "1  0.0   0.0  0.0   0.0  0.0  ...   0.0     0.0     0.0  0.0  0.0  0.0    0.0   \n",
       "2  0.0   0.0  0.0   0.0  0.0  ...   0.0     0.0     0.0  0.0  0.0  0.0    0.0   \n",
       "3  0.0   0.0  0.0   0.0  0.0  ...   0.0     0.0     0.0  0.0  0.0  0.0    0.0   \n",
       "4  0.0   0.0  0.0   0.0  0.0  ...   0.0     0.0     0.0  0.0  0.0  0.0    0.0   \n",
       "\n",
       "   zynx  zypher  zyrtec  \n",
       "0   0.0     0.0     0.0  \n",
       "1   0.0     0.0     0.0  \n",
       "2   0.0     0.0     0.0  \n",
       "3   0.0     0.0     0.0  \n",
       "4   0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 20001 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['Resume_str'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaahc</th>\n",
       "      <th>aac</th>\n",
       "      <th>aaf</th>\n",
       "      <th>aagi</th>\n",
       "      <th>aam</th>\n",
       "      <th>aami</th>\n",
       "      <th>aap</th>\n",
       "      <th>aaron</th>\n",
       "      <th>...</th>\n",
       "      <th>zune</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zutano</th>\n",
       "      <th>zvm</th>\n",
       "      <th>zx</th>\n",
       "      <th>zxx</th>\n",
       "      <th>zynex</th>\n",
       "      <th>zynx</th>\n",
       "      <th>zypher</th>\n",
       "      <th>zyrtec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aaa  aaahc  aac  aaf  aagi  aam  aami  aap  aaron  ...  zune  zurich  \\\n",
       "0  0.0  0.0    0.0  0.0  0.0   0.0  0.0   0.0  0.0    0.0  ...   0.0     0.0   \n",
       "1  0.0  0.0    0.0  0.0  0.0   0.0  0.0   0.0  0.0    0.0  ...   0.0     0.0   \n",
       "2  0.0  0.0    0.0  0.0  0.0   0.0  0.0   0.0  0.0    0.0  ...   0.0     0.0   \n",
       "3  0.0  0.0    0.0  0.0  0.0   0.0  0.0   0.0  0.0    0.0  ...   0.0     0.0   \n",
       "4  0.0  0.0    0.0  0.0  0.0   0.0  0.0   0.0  0.0    0.0  ...   0.0     0.0   \n",
       "\n",
       "   zutano  zvm   zx  zxx  zynex  zynx  zypher  zyrtec  \n",
       "0     0.0  0.0  0.0  0.0    0.0   0.0     0.0     0.0  \n",
       "1     0.0  0.0  0.0  0.0    0.0   0.0     0.0     0.0  \n",
       "2     0.0  0.0  0.0  0.0    0.0   0.0     0.0     0.0  \n",
       "3     0.0  0.0  0.0  0.0    0.0   0.0     0.0     0.0  \n",
       "4     0.0  0.0  0.0  0.0    0.0   0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 20000 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2462, 20000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       19\n",
       "1       19\n",
       "2       19\n",
       "3       19\n",
       "4       19\n",
       "        ..\n",
       "2479     6\n",
       "2480     6\n",
       "2481     6\n",
       "2482     6\n",
       "2483     6\n",
       "Name: Category, Length: 2462, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(data,result,test_size=0.2,random_state=132)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.15821501014199\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "gnb=MultinomialNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "y_p=gnb.predict(X_test)\n",
    "print(accuracy_score(y_test,y_p)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.649087221095336\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "svc=SVC()\n",
    "svc.fit(X_train,y_train)\n",
    "y_p=svc.predict(X_test)\n",
    "print(accuracy_score(y_test,y_p)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.073022312373226\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "dt=DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)\n",
    "y_p=dt.predict(X_test)\n",
    "print(accuracy_score(y_test,y_p)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.2292089249493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.90      0.76        31\n",
      "           1       0.50      0.43      0.47        23\n",
      "           2       0.71      0.42      0.53        12\n",
      "           3       0.83      0.25      0.38        20\n",
      "           4       0.33      0.06      0.10        17\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.59      0.77      0.67        22\n",
      "           7       0.62      0.54      0.58        24\n",
      "           9       0.37      0.57      0.45        23\n",
      "          10       0.70      0.95      0.81        20\n",
      "          11       0.71      0.86      0.77        28\n",
      "          12       0.67      0.19      0.30        31\n",
      "          13       0.85      0.58      0.69        19\n",
      "          14       0.67      0.67      0.67        18\n",
      "          15       0.61      0.61      0.61        23\n",
      "          16       0.72      0.57      0.63        23\n",
      "          17       0.69      0.50      0.58        22\n",
      "          18       0.39      0.65      0.49        20\n",
      "          19       0.61      0.81      0.69        21\n",
      "          20       0.58      0.86      0.69        22\n",
      "          21       0.45      0.56      0.50        16\n",
      "          22       0.36      0.38      0.37        24\n",
      "          23       0.72      0.96      0.82        24\n",
      "\n",
      "    accuracy                           0.59       493\n",
      "   macro avg       0.58      0.57      0.55       493\n",
      "weighted avg       0.60      0.59      0.56       493\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/namanmuktha/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/namanmuktha/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/namanmuktha/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "rfc=RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)\n",
    "y_p=rfc.predict(X_test)\n",
    "print(accuracy_score(y_test,y_p)*100)\n",
    "print(classification_report(y_test,y_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.79 s, sys: 1.23 s, total: 5.03 s\n",
      "Wall time: 5.38 s\n",
      "54.563894523326574\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = OneVsRestClassifier(KNeighborsClassifier())\n",
    "%time clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "print(accuracy_score(y_test,prediction)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_report = classification_report(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.87      0.71        31\n",
      "           1       0.47      0.35      0.40        23\n",
      "           2       0.83      0.42      0.56        12\n",
      "           3       0.50      0.20      0.29        20\n",
      "           4       0.38      0.18      0.24        17\n",
      "           5       0.50      0.20      0.29        10\n",
      "           6       0.75      0.55      0.63        22\n",
      "           7       0.75      0.50      0.60        24\n",
      "           9       0.43      0.52      0.47        23\n",
      "          10       0.80      0.80      0.80        20\n",
      "          11       0.75      0.86      0.80        28\n",
      "          12       0.25      0.06      0.10        31\n",
      "          13       0.81      0.68      0.74        19\n",
      "          14       0.58      0.61      0.59        18\n",
      "          15       0.57      0.74      0.64        23\n",
      "          16       0.43      0.39      0.41        23\n",
      "          17       0.62      0.45      0.53        22\n",
      "          18       0.28      0.55      0.37        20\n",
      "          19       0.62      0.71      0.67        21\n",
      "          20       0.46      0.77      0.58        22\n",
      "          21       0.38      0.56      0.45        16\n",
      "          22       0.42      0.54      0.47        24\n",
      "          23       0.61      0.71      0.65        24\n",
      "\n",
      "    accuracy                           0.55       493\n",
      "   macro avg       0.56      0.53      0.52       493\n",
      "weighted avg       0.55      0.55      0.53       493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.1 s, sys: 1.65 s, total: 58.7 s\n",
      "Wall time: 10.7 s\n",
      "67.95131845841786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.84      0.78        31\n",
      "           1       0.67      0.61      0.64        23\n",
      "           2       0.64      0.58      0.61        12\n",
      "           3       0.69      0.45      0.55        20\n",
      "           4       0.40      0.35      0.38        17\n",
      "           5       0.60      0.30      0.40        10\n",
      "           6       0.81      0.77      0.79        22\n",
      "           7       0.75      0.75      0.75        24\n",
      "           9       0.44      0.70      0.54        23\n",
      "          10       0.90      0.95      0.93        20\n",
      "          11       0.89      0.89      0.89        28\n",
      "          12       0.71      0.32      0.44        31\n",
      "          13       0.93      0.74      0.82        19\n",
      "          14       0.67      0.67      0.67        18\n",
      "          15       0.72      0.78      0.75        23\n",
      "          16       0.68      0.65      0.67        23\n",
      "          17       0.79      0.68      0.73        22\n",
      "          18       0.48      0.65      0.55        20\n",
      "          19       0.75      0.86      0.80        21\n",
      "          20       0.57      0.77      0.65        22\n",
      "          21       0.55      0.69      0.61        16\n",
      "          22       0.52      0.54      0.53        24\n",
      "          23       0.83      0.79      0.81        24\n",
      "\n",
      "    accuracy                           0.68       493\n",
      "   macro avg       0.68      0.67      0.66       493\n",
      "weighted avg       0.69      0.68      0.68       493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = OneVsRestClassifier(LogisticRegression(C=100,solver='liblinear'))\n",
    "%time clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "print(accuracy_score(y_test,prediction)*100)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_job.pkl']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n",
    "joblib.dump(clf, 'model_job.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sai', 'kiran', 'b', 'l', 'last', 'updat', 'st', 'octob', 'linkedin', 'github', 'bayyanakiran', 'gmail', 'com', 'hyderabad', 'telangana', 'india', 'educ', 'experi', 'cmr', 'colleg', 'engin', 'callippus', 'solut', 'data', 'analyst', 'june', 'august', 'hyderabad', 'telangana', 'remot']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/namanmuktha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/namanmuktha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove unwanted characters (replace with whitespace)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "    \n",
    "    # Remove extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = ''.join([c for c in text if c not in string.punctuation])\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # Stemming\n",
    "    lang = \"english\"\n",
    "    stemmer = SnowballStemmer(lang)\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Example usage:\n",
    "input_text = \"\"\"\n",
    "Sai Kiran B L S\n",
    "\n",
    "Last Updated on 1st October 2023\n",
    "\n",
    "LinkedIn| Github| bayyanakiran@gmail.com | 7416612772 | Hyderabad,Telangana,India\n",
    "\n",
    "EDUCATION\n",
    "\n",
    "EXPERIENCE\n",
    "\n",
    "CMR COLLEGE OF ENGINEER- CALLIPPUS SOLUTIONS | Data Analyst\n",
    "June 2022 – August 2022 | Hyderabad,Telangana (remote)\n",
    "...\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "preprocessed_text = preprocess_text(input_text)\n",
    "print(preprocessed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text_tfidf = tfidf_vectorizer.transform(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/namanmuktha/anaconda3/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 6,  6,  6,  6,  3,  6,  6,  4,  6,  6,  6,  6, 12,  6,  6,  7, 23,\n",
       "        2,  6,  2, 15,  6,  6, 20,  7,  4, 17,  6,  6,  2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(new_text_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future Stacks Present in Resume:\n",
      "['\\n', ' ', ' ', '\\n', ' ', 'l', '\\n', ' ', ' ', 's', 's', 's', ' ', 'S', 's', 's', ' ', 'S', '\\n', ' ', ' ', 'l', '\\n', ' ', 'l', 's', ' ', 'S', '\\n', ' ', 'b', 's', '\\n', 's', ' ', 's', '\\n', 's', ' ', 'S', ' ', 'l', '\\n', 's', ' ', 'l', 's', '\\n', 'B', ' ', ' ', 'l', 's', '\\n', 'B', 's', '\\n', 'B', 'l', '\\n', 'B', 'l', '\\n', 'B', ' ', ' ', 'B', ' ', 'b', 'l', 's', '\\n', 'B', ' ', 's', ' ', 'B', '\\n', 'S', ' ', 'l', '\\n', 'b', ' ', ' ', ' ', 'S', ' ', 'S', '\\n', 'l', ' ', '\\n', ' ', '\\n', ' ', 's', '\\n', ' ', '.', '.', ',', ' ', ',', ' ', 'b', 's', '\\n', 'b', 's', 'l', ' ', 'S', 's', 's', ' ', 'S', '\\n', 'b', 's', '\\n', ' ', 'S', '\\n', 'l', ' ', ' ', '\\n', 'l', ' ', 's', '\\n', 'l', ' ', 's', '\\n', ' ', '\\n', ' ', '\\n', ' ', 's', ' ', 'l', '\\n', ' ', 'S', ' ', 'S', 's', 's', '\\n', 'l', 'b', 'l', ' ', ' ', '\\n', ' ', 'L', '\\n', ' ', 'b', 'l', ' ', 'l', '\\n', 's', ' ', ' ', 'l', '\\n', ' ', 's', 'l', ' ', 's', ' ', 's', '\\n', ' ', '\\n', 's', ' ', 'l', ' ', 'l', '\\n', ' ', ' ', '\\n', ' ', ' ', 'l', '\\n', ' ', 'b', 's', '\\n', ' ', 'l', ' ', 'l', 'l', ' ', 'l', '\\n', 'l', ' ', 'l', '\\n', 's', ' ', ' ', 'l', '\\n', 'l', ' ', '\\n', 'L', ' ', 'l', ' ', 'l', 's', '\\n', 's', ' ', 'l', '\\n', 's', 's', ' ', '\\n', 's', 's', ' ', 's', '\\n', 'l', ' ', 'l', ' ', 'l', 's', ' ', 's', '\\n', 'l', '\\n', 'l', '\\n', ' ', 'B', 's', '\\n', 'b', 'l', ' ', 's', ' ', 's', '\\n', ' ', 'l', ' ', 'l', '\\n', 's', 'l', ' ', ' ', 'l', '\\n', 's', ' ', 'l', ' ', 'l', '\\n', ' ', 'l', 's', '\\n', ' ', ' ', 'l', '\\n', 's', 's', ' ', 'b', ' ', 'l', 's', ' ', 's', '\\n', ' ', '\\n', ' ', ' ', 'L', '\\n', ' ', 'S', 's', ' ', 'l', '\\n', ' ', '\\n', 'b', 'l', ' ', ' ', 'l', '\\n', 'S', 'l', 'l', ' ', 'l', '\\n', 'S', 'l', 'l', ' ', '\\n', 'S', 'l', ' ', 's', '\\n', 'S', 'l', 'l', ' ', 'l', 's', '\\n', 'S', 'l', 's', 's', ' ', '\\n', 'S', ' ', 's', ' ', 'l', '\\n', 'S', ' ', 's', '\\n', 'S', ' ', 'b', 's', '\\n', 'S', ' ', ' ', 'l', '\\n', 'S', 'l', ' ', 'l', ' ', 'l', '\\n', 'S', ' ', 'l', ' ', 'l', '\\n', 'S', ' ', 's', ' ', 'l', '\\n', 'S', 'l', ' ', ' ', ' ', 'l', ' ', 'l', '\\n', 'S', ' ', 'l', 'l', '\\n', 'S', ' ', 'b', 's', '\\n', 'S', ' ', 'B', 'l', '\\n', 's', ' ', '\\n', 'b', ' ', ' ', 'b', 'l', ' ', 'l', '\\n', 'l', ' ', ' ', 'l', '\\n', 'b', 'l', ' ', 'l', '\\n', ' ', 'b', ' ', 'l', '\\n', ' ', 'L', ' ', 'L', '\\n', 'l', ' ', 'L', ' ', 's', 's', ' ', 'L', '\\n', ' ', 'L', ' ', 'L', '\\n', 'l', ' ', 'l', ' ', '\\n', ' ', ' ', 's', ' ', '\\n', 'b', 's', '\\n', 'l', ' ', 'l', 'l', ' ', '\\n', ' ', '\\n', ' ', 'l', ' ', '\\n', '\\n', '\\n', 's', '\\n', ' ', ' ', ' ', 'l', ' ', 'l', 's', ' ', ' ', ' ', 's', 's', '\\n', '\\n', 'l', ',', ' ', 's', ' ', ' ', 'l', ' ', 'l', 's', ' ', ' ', ' ', 'l', 's', ' ', ' ', ' ', 's', '\\n', '\\n', ' ', ' ', '\\n', ' ', 'l', '\\n', ' ', ' ', 's', '\\n', 'l', ' ', 'l', '\\n', ' ', 's', ' ', 'S', 's', 's', '\\n', 's', ' ', ' ', 'l', 's', ' ', 's', '\\n', 'B', 'b', 'l', ' ', 'l', 's', 's', '\\n', 'B', ' ', 'l', '\\n', 'B', 'l', 'b', 's', ' ', ' ', 'S', 's', 's', '\\n', 'b', ' ', ' ', ' ', 'l', ' ', '\\n', 'b', ' ', 'b', ' ', 'l', '\\n', 'l', ' ', ' ', 'l', '\\n', ' ', '\\n', ' ', 's', '\\n', 'l', 'l', 'b', ' ', 'b', 's', ' ', 'b', 's', '\\n', 's', ' ', 'l', 'l', '\\n', ' ', ' ', 'S', 's', 's', '\\n', 'l', ' ', ' ', 'l', 's', '\\n', 'l', ' ', ' ', '\\n', 'l', ' ', 's', ' ', ' ', 's', '\\n', 'l', ' ', ' ', 'l', '\\n', 's', 'b', ' ', 's', ' ', 's', ' ', 's', '\\n', 's', 'b', ' ', 'L', ' ', 'l', ' ', 'L', '\\n', ' ', 'S', ' ', 'S', ' ', 'S', 'S', '\\n', ' ', 'l', 'l', '\\n', ' ', '\\n', 'l', 'b', 'l', ' ', 'l', 's', '\\n', ' ', 'l', '\\n', ' ', 'l', '\\n', 's', ' ', 'l', '\\n', 's', 'l', ' ', ' ', 's', '\\n', 's', ' ', 's', ' ', 'l', '\\n', ' ', '\\n', 'L', ' ', '\\n', 's', ' ', 'l', '\\n', ' ', '\\n', 's', 'b', 'l', ' ', '\\n', ' ', 'l', ' ', ' ', 's', ' ', '\\n', 's', 'l', ' ', ' ', 'l', 's', ' ', 's', '\\n', 's', 'l', ' ', 'L', ' ', 'l', 's', '\\n', 'l', 'B', 's', ' ', 'B', 'l', 's', 's', '\\n', 'l', 'B', 's', ' ', ' ', 'l', 's', '\\n', 's', ' ', 'l', ' ', 'l', '\\n', 's', ' ', 'L', 's', ' ', '\\n', ' ', 'L', 's', 's', '\\n', 'b', 'l', ' ', 's', '\\n', 'b', 'l', ' ', ' ', 'b', 's', '\\n', 'b', 'l', ' ', '\\n', 'b', 'l', ' ', 'l', 's', '\\n', ' ', 'l', '\\n', ' ', '\\n', ' ', '\\n', ' ', ' ', 's', 'b', ' ', '\\n', ' ', 'l', 's', '\\n', ' ', '\\n', 's', 's', ' ', '\\n', ' ', 'l', ' ', 'l', '\\n', ' ', 'S', 's', ' ', 'l', '\\n', 'S', 'l', 'l', ' ', '\\n', 'S', 'l', 'l', ' ', 'S', ' ', 'l', '\\n', 'S', 'l', ' ', 'B', 's', '\\n', 'S', 'l', ' ', 's', ' ', '\\n', 'S', 'l', ' ', 'l', 's', '\\n', 'S', 'l', ' ', 's', '\\n', 'S', ' ', 'l', '\\n', 'S', ' ', 's', '\\n', 'S', ' ', '\\n', 'S', ' ', ' ', 'S', 's', 's', '\\n', 'S', ' ', ' ', 'l', '\\n', 'S', ' ', ' ', ' ', 'S', 's', 's', '\\n', 'S', ' ', 's', ' ', ' ', 'S', 's', 's', '\\n', 'S', 'l', ' ', 's', '\\n', 'S', 'l', 'S', ' ', 'B', 's', '\\n', 'S', ' ', 'b', 's', ' ', 'l', ' ', 'l', '\\n', 'S', ' ', 'l', ' ', 'l', '\\n', 'S', ' ', 'b', 's', '\\n', 'S', 'B', 's', ' ', 'S', 'l', ' ', '\\n', 'S', 'b', 's', ' ', '\\n', 'S', 'l', ' ', ' ', 'b', 'l', ' ', 'l', '\\n', 'S', ' ', 's', '\\n', 'S', ' ', 'l', 'l', '\\n', 'S', ' ', 'b', 's', '\\n', 'S', ' ', 's', '\\n', 's', ' ', 'S', 'l', ' ', 'l', 's', '\\n', 'b', ' ', 'l', ' ', '\\n', 'l', ' ', ' ', ' ', 'L', ' ', 'L', ' ', '\\n', 'b', ' ', '\\n', 'l', ' ', 's', '\\n', ' ', ' ', '\\n', ' ', 'l', '\\n', ' ', ' ', 's', 's', 's', ' ', 'S', 's', 's', ' ', 'S', '\\n', ' ', ' ', 'l', '\\n', ' ', 'l', 's', ' ', 'S', '\\n', ' ', 'b', 's', '\\n', 's', ' ', 's', '\\n', 's', ' ', 'S', ' ', 'l', '\\n', 's', ' ', 'l', 's', '\\n', 'B', ' ', ' ', 'l', 's', '\\n', 'B', 's', '\\n', 'B', 'l', '\\n', 'B', 'l', '\\n', 'B', ' ', ' ', 'B', ' ', 'b', 'l', 's', '\\n', 'B', ' ', 's', ' ', 'B', '\\n', 'S', ' ', 'l', '\\n', 'b', ' ', ' ', ' ', 'S', ' ', 'S', '\\n', 'l', ' ', '\\n', ' ', '\\n', ' ', 's', '\\n', ' ', '.', '.', ',', ' ', ',', ' ', 'b', 's', '\\n', 'b', 's', 'l', ' ', 'S', 's', 's', ' ', 'S', '\\n', 'b', 's', '\\n', ' ', 'S', '\\n', 'l', ' ', ' ', '\\n', 'l', ' ', 's', '\\n', 'l', ' ', 's', '\\n', ' ', '\\n', ' ', '\\n', ' ', 's', ' ', 'l', '\\n', ' ', 'S', ' ', 'S', 's', 's', '\\n', 'l', 'b', 'l', ' ', ' ', '\\n', ' ', 'L', '\\n', ' ', 'b', 'l', ' ', 'l', '\\n', 's', ' ', ' ', 'l', '\\n', ' ', 's', 'l', ' ', 's', ' ', 's', '\\n', ' ', '\\n', 's', ' ', 'l', ' ', 'l', '\\n', ' ', ' ', '\\n', ' ', ' ', 'l', '\\n', ' ', 'b', 's', '\\n', ' ', 'l', ' ', 'l', 'l', ' ', 'l', '\\n', 'l', ' ', 'l', '\\n', 's', ' ', ' ', 'l', '\\n', 'l', ' ', '\\n', 'L', ' ', 'l', ' ', 'l', 's', '\\n', 's', ' ', 'l', '\\n', 's', 's', ' ', '\\n', 's', 's', ' ', 's', '\\n', 'l', ' ', 'l', ' ', 'l', 's', ' ', 's', '\\n', 'l', '\\n', 'l', '\\n', ' ', 'B', 's', '\\n', 'b', 'l', ' ', 's', ' ', 's', '\\n', ' ', 'l', ' ', 'l', '\\n', 's', 'l', ' ', ' ', 'l', '\\n', 's', ' ', 'l', ' ', 'l', '\\n', ' ', 'l', 's', '\\n', ' ', ' ', 'l', '\\n', 's', 's', ' ', 'b', ' ', 'l', 's', ' ', 's', '\\n', ' ', '\\n', ' ', ' ', 'L', '\\n', ' ', 'S', 's', ' ', 'l', '\\n', ' ', '\\n', 'b', 'l', ' ', ' ', 'l', '\\n', 'S', 'l', 'l', ' ', 'l', '\\n', 'S', 'l', 'l', ' ', '\\n', 'S', 'l', ' ', 's', '\\n', 'S', 'l', 'l', ' ', 'l', 's', '\\n', 'S', 'l', 's', 's', ' ', '\\n', 'S', ' ', 's', ' ', 'l', '\\n', 'S', ' ', 's', '\\n', 'S', ' ', 'b', 's', '\\n', 'S', ' ', ' ', 'l', '\\n', 'S', 'l', ' ', 'l', ' ', 'l', '\\n', 'S', ' ', 'l', ' ', 'l', '\\n', 'S', ' ', 's', ' ', 'l', '\\n', 'S', 'l', ' ', ' ', ' ', 'l', ' ', 'l', '\\n', 'S', ' ', 'l', 'l', '\\n', 'S', ' ', 'b', 's', '\\n', 'S', ' ', 'B', 'l', '\\n', 's', ' ', '\\n', 'b', ' ', ' ', 'b', 'l', ' ', 'l', '\\n', 'l', ' ', ' ', 'l', '\\n', 'b', 'l', ' ', 'l', '\\n', ' ', 'b', ' ', 'l', '\\n', ' ', 'L', ' ', 'L', '\\n', 'l', ' ', 'L', ' ', 's', 's', ' ', 'L', '\\n', ' ', 'L', ' ', 'L', '\\n', 'l', ' ', 'l', ' ', '\\n', ' ', ' ', 's', ' ', '\\n', 'b', 's', '\\n', 'l', ' ', 'l', 'l', ' ', '\\n', ' ', '\\n', ' ', 'l', ' ', '\\n']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def check_future_stacks_in_resume(resume_text, future_stacks):\n",
    "    present_stacks = []\n",
    "\n",
    "    # Convert the resume text to lowercase for case-insensitive matching\n",
    "    resume_text_lower = resume_text.lower()\n",
    "\n",
    "    # Iterate through each future stack and check if it's present in the resume\n",
    "    for stack in future_stacks:\n",
    "        # Use regular expression for word boundary matching\n",
    "        pattern = re.compile(r'\\b' + re.escape(stack.lower()) + r'\\b')\n",
    "        \n",
    "        if re.search(pattern, resume_text_lower):\n",
    "            present_stacks.append(stack)\n",
    "\n",
    "    return present_stacks\n",
    "\n",
    "# Example resume text\n",
    "resume_text = \"\"\"\n",
    "Sai Kiran B L S\n",
    "\n",
    "Last Updated on 1st October 2023\n",
    "\n",
    "LinkedIn| Github| bayyanakiran@gmail.com | 7416612772 | Hyderabad,Telangana,India\n",
    "\n",
    "EDUCATION\n",
    "\n",
    "EXPERIENCE\n",
    "\n",
    "CMR COLLEGE OF ENGINEER- CALLIPPUS SOLUTIONS | Data Analyst\n",
    "June 2022 – August 2022 | Hyderabad,Telangana (remote)\n",
    "...\n",
    "...\n",
    "\"\"\"\n",
    "future_stacks=\"\"\"\n",
    "3D Printing/Additive Manufacturing\n",
    "5G Technology\n",
    "Advanced Driver Assistance Systems (ADAS)\n",
    "Advanced Manufacturing Technology\n",
    "Advanced Materials Science\n",
    "Advanced Robotics\n",
    "Autonomous Drones\n",
    "Autonomous Shipping Technology\n",
    "Autonomous Vehicles\n",
    "Big Data Analytics\n",
    "Bioinformatics\n",
    "Biotechnology\n",
    "Blockchain\n",
    "Brain-Computer Interface (BCI) Wearables\n",
    "Brain-Computer Interfaces (BCI)\n",
    "CRISPR Technology\n",
    "Carbon Capture and Storage (CCS)\n",
    "Cloud Computing\n",
    "Cognitive Computing\n",
    "Computer Vision\n",
    "Containerization (e.g., Docker, Kubernetes)\n",
    "Cyber-Physical Systems (CPS)\n",
    "Cybersecurity\n",
    "Data Science\n",
    "Decentralized Finance (DeFi)\n",
    "Digital Therapeutics\n",
    "Digital Twins\n",
    "Edge AI\n",
    "Edge Computing\n",
    "Energy Harvesting Technology\n",
    "Energy Storage Systems\n",
    "Explainable AI (XAI)\n",
    "Federated Learning\n",
    "Food Traceability Technology\n",
    "Fusion Energy Technology\n",
    "Generative Adversarial Networks (GANs)\n",
    "Genetic Engineering\n",
    "Gesture Control Technology\n",
    "High-Performance Computing (HPC)\n",
    "Human Augmentation Technology\n",
    "Humanoid Robotics\n",
    "Hydrogen Fuel Cell Technology\n",
    "Hyperloop Technology\n",
    "Insect Farming Technology\n",
    "Interplanetary Internet\n",
    "Low-Code/No-Code Development Platforms\n",
    "Metaverse Development\n",
    "Microservices Architecture\n",
    "Microservices Mesh\n",
    "Multi-Experience Development Platforms (MXDPs)\n",
    "Nanotechnology\n",
    "Neurotechnology\n",
    "Next-Generation Batteries\n",
    "Non-Fungible Tokens (NFTs)\n",
    "Ocean Cleanup Technology\n",
    "Personalized Medicine Technology\n",
    "Precision Agriculture Technology\n",
    "Predictive Analytics\n",
    "Predictive Maintenance Technology\n",
    "Progressive Web Applications (PWAs)\n",
    "Quantum Cryptography\n",
    "Quantum Machine Learning\n",
    "Quantum Sensing Technology\n",
    "Regenerative Medicine\n",
    "Renewable Energy Technology\n",
    "Satellite Technology\n",
    "Self-Healing Concrete\n",
    "Self-driving Tractors\n",
    "Self-healing Materials\n",
    "Serverless Computing\n",
    "Smart Cities Technology\n",
    "Smart Contracts\n",
    "Smart Fabrics\n",
    "Smart Grid Technology\n",
    "Solar Panel Technology\n",
    "Space Exploration Technology\n",
    "Space Tourism Technology\n",
    "Supercritical CO2 Power Cycle Technology\n",
    "Swarm Intelligence\n",
    "Swarm Robotics\n",
    "Synthetic Biology\n",
    "Transparent Computing\n",
    "Urban Air Mobility Technology\n",
    "Vertical Farming Technology\n",
    "Wearable Technology\n",
    "Wind Turbine Technology\n",
    "Machine Learning (ML)\n",
    "Natural Language Processing (NLP)\n",
    "Deep Learning (DL)\n",
    "Virtual Reality (VR)\n",
    "Internet of Things (IoT)\n",
    "Robotics\n",
    "Artificial Intelligence (AI)\n",
    "Quantum Computing\n",
    "Augmented Reality (AR)\n",
    "\n",
    "\n",
    "User\n",
    "I need 183 total values with correct wordss\n",
    "ChatGPT\n",
    "Certainly, here's the complete list of 183 values with corrected words:\n",
    "\n",
    "3D Food Printing\n",
    "6G Technology\n",
    "AI-driven Drug Discovery\n",
    "Aquaculture Technology\n",
    "Automated Warehousing Systems\n",
    "Autonomous Underwater Vehicles (AUVs)\n",
    "Biodegradable Plastics\n",
    "Biomimicry Technology\n",
    "Blockchain-based Voting Systems\n",
    "Carbon Capture and Utilization (CCU)\n",
    "Carbon Nanotube Technology\n",
    "Climate Engineering Technology\n",
    "Cognitive Automation\n",
    "Cognitive Cities\n",
    "Collaborative Robots (Cobots)\n",
    "Continuous Intelligence\n",
    "Cryptocurrency Payment Systems\n",
    "Digital Farming Platforms\n",
    "Digital Identity Management\n",
    "Digital Twins of Cities\n",
    "Digital Watermarking Technology\n",
    "Distributed Autonomous Organizations (DAOs)\n",
    "Distributed Ledger Technology (DLT)\n",
    "Dynamic Spectrum Sharing (DSS)\n",
    "Edge Intelligence\n",
    "Energy-Efficient Computing\n",
    "Flexible Electronics\n",
    "Graphene Technology\n",
    "Green Technology\n",
    "Hydroponics Technology\n",
    "Hyperscale Data Centers\n",
    "Hypersonic Transportation Technology\n",
    "In-Memory Computing\n",
    "Living Architecture\n",
    "Memristor Technology\n",
    "Neuromorphic Computing\n",
    "Neurosymbolic AI\n",
    "Ocean Thermal Energy Conversion (OTEC)\n",
    "Personal Air Vehicles (PAVs)\n",
    "Personalized Learning Platforms\n",
    "Plant-Based Bioplastics\n",
    "Plant-Based Meat Alternatives\n",
    "Precision Agriculture Technology\n",
    "Precision Livestock Farming\n",
    "Predictive Logistics\n",
    "Programmable Cities\n",
    "Programmable DNA Nanobots\n",
    "Programmable Matter\n",
    "Programmable Metamaterials\n",
    "Quantum Annealing\n",
    "Quantum Communication\n",
    "Quantum Internet\n",
    "Quantum Key Distribution (QKD)\n",
    "Quantum Materials\n",
    "Quantum Networking\n",
    "Quantum-resistant Cryptography\n",
    "Remote Healthcare Technology\n",
    "Remote Sensing Technology\n",
    "Satellite Internet\n",
    "Satellite Servicing Technology\n",
    "Self-Driving Boats\n",
    "Self-Driving Construction Equipment\n",
    "Self-Driving Forklifts\n",
    "Self-Driving Trucks\n",
    "Smart Clothing\n",
    "Smart Dust\n",
    "Smart Furniture\n",
    "Smart Irrigation Systems\n",
    "Smart Packaging Technology\n",
    "Smart Traffic Management Systems\n",
    "Smart Waste Management Systems\n",
    "Solar Windows\n",
    "Solid-State Batteries\n",
    "Space Debris Removal Technology\n",
    "Space Elevator Technology\n",
    "Space Habitats\n",
    "Space-Based Solar Power\n",
    "Space-based Manufacturing\n",
    "Supply Chain Traceability Technology\n",
    "Swarm Drones\n",
    "Swarm Intelligence\n",
    "Swarm Robotics\n",
    "Synthetic Diamonds\n",
    "Transparent Solar Panels\n",
    "Urban Vertical Farming\n",
    "Vertical Takeoff and Landing (VTOL) Aircraft\n",
    "Zero-Carbon Cement\n",
    "Zero-Knowledge Proofs\n",
    "3D Printing/Additive Manufacturing\n",
    "5G Technology\n",
    "Advanced Driver Assistance Systems (ADAS)\n",
    "Advanced Manufacturing Technology\n",
    "Advanced Materials Science\n",
    "Advanced Robotics\n",
    "Autonomous Drones\n",
    "Autonomous Shipping Technology\n",
    "Autonomous Vehicles\n",
    "Big Data Analytics\n",
    "Bioinformatics\n",
    "Biotechnology\n",
    "Blockchain\n",
    "Brain-Computer Interface (BCI) Wearables\n",
    "Brain-Computer Interfaces (BCI)\n",
    "CRISPR Technology\n",
    "Carbon Capture and Storage (CCS)\n",
    "Cloud Computing\n",
    "Cognitive Computing\n",
    "Computer Vision\n",
    "Containerization (e.g., Docker, Kubernetes)\n",
    "Cyber-Physical Systems (CPS)\n",
    "Cybersecurity\n",
    "Data Science\n",
    "Decentralized Finance (DeFi)\n",
    "Digital Therapeutics\n",
    "Digital Twins\n",
    "Edge AI\n",
    "Edge Computing\n",
    "Energy Harvesting Technology\n",
    "Energy Storage Systems\n",
    "Explainable AI (XAI)\n",
    "Federated Learning\n",
    "Food Traceability Technology\n",
    "Fusion Energy Technology\n",
    "Generative Adversarial Networks (GANs)\n",
    "Genetic Engineering\n",
    "Gesture Control Technology\n",
    "High-Performance Computing (HPC)\n",
    "Human Augmentation Technology\n",
    "Humanoid Robotics\n",
    "Hydrogen Fuel Cell Technology\n",
    "Hyperloop Technology\n",
    "Insect Farming Technology\n",
    "Interplanetary Internet\n",
    "Low-Code/No-Code Development Platforms\n",
    "Metaverse Development\n",
    "Microservices Architecture\n",
    "Microservices Mesh\n",
    "Multi-Experience Development Platforms (MXDPs)\n",
    "Nanotechnology\n",
    "Neurotechnology\n",
    "Next-Generation Batteries\n",
    "Non-Fungible Tokens (NFTs)\n",
    "Ocean Cleanup Technology\n",
    "Personalized Medicine Technology\n",
    "Precision Agriculture Technology\n",
    "Predictive Analytics\n",
    "Predictive Maintenance Technology\n",
    "Progressive Web Applications (PWAs)\n",
    "Quantum Cryptography\n",
    "Quantum Machine Learning\n",
    "Quantum Sensing Technology\n",
    "Regenerative Medicine\n",
    "Renewable Energy Technology\n",
    "Satellite Technology\n",
    "Self-Healing Concrete\n",
    "Self-driving Tractors\n",
    "Self-healing Materials\n",
    "Serverless Computing\n",
    "Smart Cities Technology\n",
    "Smart Contracts\n",
    "Smart Fabrics\n",
    "Smart Grid Technology\n",
    "Solar Panel Technology\n",
    "Space Exploration Technology\n",
    "Space Tourism Technology\n",
    "Supercritical CO2 Power Cycle Technology\n",
    "Swarm Intelligence\n",
    "Swarm Robotics\n",
    "Synthetic Biology\n",
    "Transparent Computing\n",
    "Urban Air Mobility Technology\n",
    "Vertical Farming Technology\n",
    "Wearable Technology\n",
    "Wind Turbine Technology\n",
    "Machine Learning (ML)\n",
    "Natural Language Processing (NLP)\n",
    "Deep Learning (DL)\n",
    "Virtual Reality (VR)\n",
    "Internet of Things (IoT)\n",
    "Robotics\n",
    "Artificial Intelligence (AI)\n",
    "Quantum Computing\n",
    "Augmented Reality (AR)\n",
    "\"\"\"\n",
    "# Call the function to check for the presence of future stacks\n",
    "present_stacks = check_future_stacks_in_resume(resume_text, future_stacks)\n",
    "\n",
    "# Print the future stacks present in the resume\n",
    "print(\"Future Stacks Present in Resume:\")\n",
    "print(present_stacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "technology_skills = {\n",
    "    \"3D Printing/Additive Manufacturing\": [\"CAD Design\", \"Material Science\", \"Manufacturing Processes\"],\n",
    "    \"5G Technology\": [\"Wireless Communication\", \"Network Infrastructure\", \"Protocol Knowledge\"],\n",
    "    \"Advanced Driver Assistance Systems (ADAS)\": [\"Computer Vision\", \"Machine Learning\", \"Embedded Systems\"],\n",
    "    \"Advanced Manufacturing Technology\": [\"Automation\", \"Process Optimization\", \"Quality Control\"],\n",
    "    \"Advanced Materials Science\": [\"Material Synthesis\", \"Characterization Techniques\", \"Nanostructures\"],\n",
    "    \"Advanced Robotics\": [\"Mechatronics\", \"Control Systems\", \"Programming\"],\n",
    "    \"Autonomous Drones\": [\"Drone Piloting\", \"Computer Vision\", \"Navigation Algorithms\"],\n",
    "    \"Autonomous Shipping Technology\": [\"Maritime Engineering\", \"Navigation Systems\", \"Remote Sensing\"],\n",
    "    \"Autonomous Vehicles\": [\"Sensor Fusion\", \"Path Planning\", \"Artificial Intelligence\"],\n",
    "    \"Big Data Analytics\": [\"Data Mining\", \"Statistical Analysis\", \"Big Data Platforms\"],\n",
    "    \"Bioinformatics\": [\"Genomics\", \"Computational Biology\", \"Biostatistics\"],\n",
    "    \"Biotechnology\": [\"Genetic Engineering\", \"Cell Culture\", \"Bioprocess Optimization\"],\n",
    "    \"Blockchain\": [\"Distributed Ledger Technology\", \"Smart Contracts\", \"Cryptography\"],\n",
    "    \"Brain-Computer Interface (BCI) Wearables\": [\"Neurotechnology\", \"Wearable Technology\", \"Signal Processing\"],\n",
    "    \"Brain-Computer Interfaces (BCI)\": [\"Neurotechnology\", \"Signal Processing\", \"Machine Learning\"],\n",
    "    \"CRISPR Technology\": [\"Genetic Engineering\", \"Molecular Biology\", \"Bioethics\"],\n",
    "    \"Carbon Capture and Storage (CCS)\": [\"Carbon Capture Technology\", \"Storage Systems\", \"Environmental Engineering\"],\n",
    "    \"Cloud Computing\": [\"Virtualization\", \"Distributed Systems\", \"Security\"],\n",
    "    \"Cognitive Computing\": [\"Natural Language Processing\", \"Machine Learning\", \"Artificial Intelligence\"],\n",
    "    \"Computer Vision\": [\"Image Processing\", \"Machine Learning\", \"Object Recognition\"],\n",
    "    \"Containerization (e.g., Docker, Kubernetes)\": [\"Container Orchestration\", \"DevOps\", \"Microservices\"],\n",
    "    \"Cyber-Physical Systems (CPS)\": [\"Embedded Systems\", \"Communication Protocols\", \"Security\"],\n",
    "    \"Cybersecurity\": [\"Network Security\", \"Penetration Testing\", \"Security Policies\"],\n",
    "    \"Data Science\": [\"Statistics\", \"Machine Learning\", \"Data Analytics\"],\n",
    "    \"Decentralized Finance (DeFi)\": [\"Blockchain\", \"Smart Contracts\", \"Cryptocurrency\"],\n",
    "    \"Digital Therapeutics\": [\"Healthcare Technology\", \"Software Development\", \"Medical Research\"],\n",
    "    \"Digital Twins\": [\"IoT\", \"Data Analytics\", \"Simulation Modeling\"],\n",
    "    \"Edge AI\": [\"Edge Computing\", \"Machine Learning\", \"Data Security\"],\n",
    "    \"Edge Computing\": [\"Distributed Computing\", \"IoT\", \"Network Architecture\"],\n",
    "    \"Energy Harvesting Technology\": [\"Renewable Energy\", \"Sensor Integration\", \"Power Management\"],\n",
    "    \"Energy Storage Systems\": [\"Battery Technology\", \"Energy Management\", \"Renewable Energy\"],\n",
    "    \"Explainable AI (XAI)\": [\"Interpretable Models\", \"Machine Learning\", \"Explanatory Visualization\"],\n",
    "    \"Federated Learning\": [\"Decentralized Machine Learning\", \"Privacy-Preserving Algorithms\", \"Data Collaboration\"],\n",
    "    \"Food Traceability Technology\": [\"Supply Chain Technology\", \"Blockchain\", \"Data Analytics\"],\n",
    "    \"Fusion Energy Technology\": [\"Nuclear Fusion\", \"Plasma Physics\", \"Energy Conversion\"],\n",
    "    \"Generative Adversarial Networks (GANs)\": [\"Machine Learning\", \"Deep Learning\", \"Neural Networks\"],\n",
    "    \"Genetic Engineering\": [\"Molecular Biology\", \"Biotechnology\", \"Genomics\"],\n",
    "    \"Gesture Control Technology\": [\"Human-Computer Interaction\", \"Sensor Technology\", \"Machine Learning\"],\n",
    "    \"High-Performance Computing (HPC)\": [\"Parallel Computing\", \"Supercomputing\", \"Performance Optimization\"],\n",
    "    \"Human Augmentation Technology\": [\"Augmented Reality\", \"Prosthetics\", \"Biomechanics\"],\n",
    "    \"Humanoid Robotics\": [\"Robotics\", \"Mechatronics\", \"Artificial Intelligence\"],\n",
    "    \"Hydrogen Fuel Cell Technology\": [\"Fuel Cell Systems\", \"Chemical Engineering\", \"Renewable Energy\"],\n",
    "    \"Hyperloop Technology\": [\"Transportation Technology\", \"Magnetic Levitation\", \"Infrastructure Design\"],\n",
    "    \"Insect Farming Technology\": [\"Entomology\", \"Agricultural Technology\", \"Sustainable Farming\"],\n",
    "    \"Interplanetary Internet\": [\"Space Communication\", \"Networking Protocols\", \"Satellite Technology\"],\n",
    "    \"Low-Code/No-Code Development Platforms\": [\"Software Development\", \"Application Design\", \"User Interface\"],\n",
    "    \"Metaverse Development\": [\"Virtual Reality\", \"Augmented Reality\", \"Game Development\"],\n",
    "    \"Microservices Architecture\": [\"Software Architecture\", \"Containerization\", \"Distributed Systems\"],\n",
    "    \"Microservices Mesh\": [\"Service Mesh\", \"Microservices Architecture\", \"API Management\"],\n",
    "    \"Multi-Experience Development Platforms (MXDPs)\": [\"Cross-Platform Development\", \"User Experience Design\", \"Mobile App Development\"],\n",
    "    \"Nanotechnology\": [\"Materials Science\", \"Nanomaterials\", \"Nanofabrication\"],\n",
    "    \"Neurotechnology\": [\"Neuroscience\", \"Brain-Computer Interfaces\", \"Neural Engineering\"],\n",
    "    \"Next-Generation Batteries\": [\"Battery Technology\", \"Materials Science\", \"Energy Storage\"],\n",
    "    \"Non-Fungible Tokens (NFTs)\": [\"Blockchain\", \"Digital Assets\", \"Cryptocurrency\"],\n",
    "    \"Ocean Cleanup Technology\": [\"Marine Engineering\", \"Environmental Science\", \"Oceanography\"],\n",
    "    \"Personalized Medicine Technology\": [\"Genomics\", \"Health Informatics\", \"Precision Medicine\"],\n",
    "    \"Precision Agriculture Technology\": [\"Agricultural Technology\", \"IoT\", \"Data Analytics\"],\n",
    "    \"Predictive Analytics\": [\"Data Science\", \"Machine Learning\", \"Statistical Modeling\"],\n",
    "    \"Predictive Maintenance Technology\": [\"Condition Monitoring\", \"IoT\", \"Data Analytics\"],\n",
    "    \"Progressive Web Applications (PWAs)\": [\"Web Development\", \"JavaScript\", \"User Experience Design\"],\n",
    "    \"Quantum Cryptography\": [\"Quantum Physics\", \"Cryptography\", \"Quantum Key Distribution\"],\n",
    "    \"Quantum Machine Learning\": [\"Quantum Computing\", \"Machine Learning\", \"Quantum Algorithms\"],\n",
    "    \"Quantum Sensing Technology\": [\"Quantum Physics\", \"Sensing Devices\", \"Quantum Metrology\"],\n",
    "    \"Regenerative Medicine\": [\"Stem Cell Research\", \"Tissue Engineering\", \"Biomedical Engineering\"],\n",
    "    \"Renewable Energy Technology\": [\"Solar Energy\", \"Wind Energy\", \"Hydropower\"],\n",
    "    \"Satellite Technology\": [\"Satellite Communication\", \"Spacecraft Systems\", \"Remote Sensing\"],\n",
    "    \"Self-Healing Concrete\": [\"Material Science\", \"Civil Engineering\", \"Structural Health Monitoring\"],\n",
    "    \"Self-driving Tractors\": [\"Autonomous Vehicles\", \"Agricultural Technology\", \"Sensor Fusion\"],\n",
    "    \"Self-healing Materials\": [\"Materials Science\", \"Polymer Chemistry\", \"Material Engineering\"],\n",
    "    \"Serverless Computing\": [\"Cloud Computing\", \"Function as a Service (FaaS)\", \"Microservices\"],\n",
    "    \"Smart Cities Technology\": [\"IoT\", \"Urban Planning\", \"Data Analytics\"],\n",
    "    \"Smart Contracts\": [\"Blockchain\", \"Smart Contract Development\", \"Cryptocurrency\"],\n",
    "    \"Smart Fabrics\": [\"Textile Technology\", \"Wearable Technology\", \"Sensor Integration\"],\n",
    "    \"Smart Grid Technology\": [\"Electrical Engineering\", \"Grid Management\", \"Renewable Energy Integration\"],\n",
    "    \"Solar Panel Technology\": [\"Photovoltaics\", \"Solar Energy\", \"Energy Harvesting\"],\n",
    "    \"Space Exploration Technology\": [\"Aerospace Engineering\", \"Rocket Science\", \"Spacecraft Systems\"],\n",
    "    \"Space Tourism Technology\": [\"Commercial Space Travel\", \"Spacecraft Design\", \"Space Tourism Operations\"],\n",
    "    \"Supercritical CO2 Power Cycle Technology\": [\"Power Generation\", \"Thermodynamics\", \"Energy Conversion\"],\n",
    "    \"Swarm Intelligence\": [\"Collective Behavior\", \"Distributed Systems\", \"Algorithms\"],\n",
    "    \"Swarm Robotics\": [\"Cooperative Robotics\", \"Decentralized Control\", \"Swarm Algorithms\"],\n",
    "    \"Synthetic Biology\": [\"Genetic Engineering\", \"Biotechnology\", \"Molecular Biology\"],\n",
    "    \"Transparent Computing\": [\"Data Security\", \"Transparency Protocols\", \"Decentralized Systems\"],\n",
    "    \"Urban Air Mobility Technology\": [\"Aerospace Engineering\", \"Drone Technology\", \"Air Traffic Management\"],\n",
    "    \"Vertical Farming Technology\": [\"Agricultural Technology\", \"Hydroponics\", \"Vertical Farming Systems\"],\n",
    "    \"Wearable Technology\": [\"Wearable Devices\", \"Sensor Integration\", \"Health Monitoring\"],\n",
    "    \"Wind Turbine Technology\": [\"Wind Energy\", \"Mechanical Engineering\", \"Power Electronics\"],\n",
    "    \"Machine Learning (ML)\": [\"Data Science\", \"Statistical Modeling\", \"Algorithm Design\"],\n",
    "    \"Natural Language Processing (NLP)\": [\"Computational Linguistics\", \"Text Processing\", \"Machine Translation\"],\n",
    "    \"Deep Learning (DL)\": [\"Neural Networks\", \"Deep Neural Networks\", \"Computer Vision\"],\n",
    "    \"Virtual Reality (VR)\": [\"Immersive Technology\", \"3D Modeling\", \"User Experience Design\"],\n",
    "    \"Internet of Things (IoT)\": [\"Embedded Systems\", \"Sensor Networks\", \"Cloud Integration\"],\n",
    "    \"Robotics\": [\"Mechanical Engineering\", \"Electrical Engineering\", \"Control Systems\"],\n",
    "    \"Artificial Intelligence (AI)\": [\"Machine Learning\", \"Natural Language Processing\", \"Computer Vision\"],\n",
    "    \"Quantum Computing\": [\"Quantum Physics\", \"Quantum Algorithms\", \"Quantum Hardware\"],\n",
    "    \"Augmented Reality (AR)\": [\"Mixed Reality\", \"Computer Vision\", \"User Interface Design\"],\n",
    "\n",
    "    # ... (add more technologies)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Technology</th>\n",
       "      <th>Skill1</th>\n",
       "      <th>Skill2</th>\n",
       "      <th>Skill3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Printing/Additive Manufacturing</td>\n",
       "      <td>CAD Design</td>\n",
       "      <td>Material Science</td>\n",
       "      <td>Manufacturing Processes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5G Technology</td>\n",
       "      <td>Wireless Communication</td>\n",
       "      <td>Network Infrastructure</td>\n",
       "      <td>Protocol Knowledge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Advanced Driver Assistance Systems (ADAS)</td>\n",
       "      <td>Computer Vision</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Embedded Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Advanced Manufacturing Technology</td>\n",
       "      <td>Automation</td>\n",
       "      <td>Process Optimization</td>\n",
       "      <td>Quality Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Advanced Materials Science</td>\n",
       "      <td>Material Synthesis</td>\n",
       "      <td>Characterization Techniques</td>\n",
       "      <td>Nanostructures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Advanced Robotics</td>\n",
       "      <td>Mechatronics</td>\n",
       "      <td>Control Systems</td>\n",
       "      <td>Programming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Autonomous Drones</td>\n",
       "      <td>Drone Piloting</td>\n",
       "      <td>Computer Vision</td>\n",
       "      <td>Navigation Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Autonomous Shipping Technology</td>\n",
       "      <td>Maritime Engineering</td>\n",
       "      <td>Navigation Systems</td>\n",
       "      <td>Remote Sensing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Autonomous Vehicles</td>\n",
       "      <td>Sensor Fusion</td>\n",
       "      <td>Path Planning</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Big Data Analytics</td>\n",
       "      <td>Data Mining</td>\n",
       "      <td>Statistical Analysis</td>\n",
       "      <td>Big Data Platforms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Technology                  Skill1  \\\n",
       "0         3D Printing/Additive Manufacturing              CAD Design   \n",
       "1                              5G Technology  Wireless Communication   \n",
       "2  Advanced Driver Assistance Systems (ADAS)         Computer Vision   \n",
       "3          Advanced Manufacturing Technology              Automation   \n",
       "4                 Advanced Materials Science      Material Synthesis   \n",
       "5                          Advanced Robotics            Mechatronics   \n",
       "6                          Autonomous Drones          Drone Piloting   \n",
       "7             Autonomous Shipping Technology    Maritime Engineering   \n",
       "8                        Autonomous Vehicles           Sensor Fusion   \n",
       "9                         Big Data Analytics             Data Mining   \n",
       "\n",
       "                        Skill2                   Skill3  \n",
       "0             Material Science  Manufacturing Processes  \n",
       "1       Network Infrastructure       Protocol Knowledge  \n",
       "2             Machine Learning         Embedded Systems  \n",
       "3         Process Optimization          Quality Control  \n",
       "4  Characterization Techniques           Nanostructures  \n",
       "5              Control Systems              Programming  \n",
       "6              Computer Vision    Navigation Algorithms  \n",
       "7           Navigation Systems           Remote Sensing  \n",
       "8                Path Planning  Artificial Intelligence  \n",
       "9         Statistical Analysis       Big Data Platforms  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(technology_skills.items()), columns=['Technology', 'Skills'])\n",
    "\n",
    "# Split the Skills list into separate columns\n",
    "df[['Skill1', 'Skill2', 'Skill3']] = pd.DataFrame(df['Skills'].tolist(), index=df.index)\n",
    "\n",
    "# Drop the original 'Skills' column\n",
    "df = df.drop(columns=['Skills'])\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 4)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entities': {'PERSON': ['John Doe\\n',\n",
       "   'XYZ University',\n",
       "   '2018',\n",
       "   'ABC Tech',\n",
       "   '2018',\n",
       "   'Django',\n",
       "   'JavaScript'],\n",
       "  'ORG': ['John Doe\\n',\n",
       "   'XYZ University',\n",
       "   '2018',\n",
       "   'ABC Tech',\n",
       "   '2018',\n",
       "   'Django',\n",
       "   'JavaScript'],\n",
       "  'DATE': ['John Doe\\n',\n",
       "   'XYZ University',\n",
       "   '2018',\n",
       "   'ABC Tech',\n",
       "   '2018',\n",
       "   'Django',\n",
       "   'JavaScript'],\n",
       "  'PRODUCT': ['John Doe\\n',\n",
       "   'XYZ University',\n",
       "   '2018',\n",
       "   'ABC Tech',\n",
       "   '2018',\n",
       "   'Django',\n",
       "   'JavaScript']},\n",
       " 'skills': ['Python', 'Machine Learning', 'Data Analysis']}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def analyze_resume(resume_text):\n",
    "    # Process the resume text using spaCy\n",
    "    doc = nlp(resume_text)\n",
    "\n",
    "    # Extract relevant information\n",
    "    entities = {ent.label_: [ent.text for ent in doc.ents] for ent in doc.ents}\n",
    "    \n",
    "    # Customize this based on your specific requirements\n",
    "    relevant_info = {\n",
    "        \"entities\": entities,\n",
    "        \"skills\": extract_skills(doc),\n",
    "        # Add more features or analysis as needed\n",
    "    }\n",
    "\n",
    "    return relevant_info\n",
    "\n",
    "def extract_skills(doc):\n",
    "    # Customize this function to extract skills from the document\n",
    "    # For example, you can look for keywords or use a pre-trained model for skills extraction\n",
    "    skills = [\"Python\", \"Machine Learning\", \"Data Analysis\"]  # Placeholder, replace with actual implementation\n",
    "    return skills\n",
    "\n",
    "# Example usage\n",
    "user_resume = \"\"\"\n",
    "John Doe\n",
    "Software Engineer\n",
    "\n",
    "Education:\n",
    "- Bachelor of Science in Computer Science, XYZ University, 2018\n",
    "\n",
    "Experience:\n",
    "- Software Developer, ABC Tech, 2018-present\n",
    "  - Developed and maintained web applications using Python and Django.\n",
    "  - Collaborated with cross-functional teams to deliver high-quality software.\n",
    "\n",
    "Skills:\n",
    "- Python\n",
    "- Django\n",
    "- JavaScript\n",
    "\"\"\"\n",
    "\n",
    "result = analyze_resume(user_resume)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
